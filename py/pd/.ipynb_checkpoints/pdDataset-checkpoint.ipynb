{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "539388ff-bb77-4ea6-8f5b-1a3fef8c39a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydataset in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (0.2.0)\n",
      "Requirement already satisfied: pandas in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from pydataset) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from pandas->pydataset) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from pandas->pydataset) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from pandas->pydataset) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from pandas->pydataset) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->pydataset) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc6671c-a1a0-4777-b704-b53bb81b406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydataset import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7b27f70-436d-4538-866d-52a573feed88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        dataset_id                                             title\n",
      "0    AirPassengers       Monthly Airline Passenger Numbers 1949-1960\n",
      "1          BJsales                 Sales Data with Leading Indicator\n",
      "2              BOD                         Biochemical Oxygen Demand\n",
      "3     Formaldehyde                     Determination of Formaldehyde\n",
      "4     HairEyeColor         Hair and Eye Color of Statistics Students\n",
      "..             ...                                               ...\n",
      "752        VerbAgg                  Verbal Aggression item responses\n",
      "753           cake                 Breakage Angle of Chocolate Cakes\n",
      "754           cbpp                 Contagious bovine pleuropneumonia\n",
      "755    grouseticks  Data on red grouse ticks from Elston et al. 2001\n",
      "756     sleepstudy       Reaction times in a sleep deprivation study\n",
      "\n",
      "[757 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c249abfc-0a1b-44c9-8bc9-318108edfd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AirPassengers, BJsales, BOD, Formaldehyde, HairEyeColor, InsectSprays, JohnsonJohnson, LakeHuron, LifeCycleSavings, Nile, OrchardSprays, PlantGrowth, Puromycin, Titanic, ToothGrowth, UCBAdmissions, UKDriverDeaths, UKgas, USAccDeaths, USArrests, USJudgeRatings, USPersonalExpenditure, VADeaths, WWWusage, WorldPhones, airmiles, airquality, anscombe, attenu, attitude, austres, cars, chickwts, co2, crimtab, discoveries, esoph, euro, faithful, freeny, infert, iris, islands, lh, longley, lynx, morley, mtcars, nhtemp, nottem, npk, occupationalStatus, precip, presidents, pressure, quakes, randu, rivers, rock, sleep, stackloss, sunspot.month, sunspot.year, sunspots, swiss, treering, trees, uspop, volcano, warpbreaks, women, acme, aids, aircondit, aircondit7, amis, aml, bigcity, brambles, breslow, calcium, cane, capability, catsM, cav, cd4, channing, city, claridge, cloth, co.transfer, coal, darwin, dogs, downs.bc, ducks, fir, frets, grav, gravity, hirose, islay, manaus, melanoma, motor, neuro, nitrofen, nodal, nuclear, paulsen, poisons, polar, remission, salinity, survival, tau, tuna, urine, wool, aids, alloauto, allograft, azt, baboon, bcdeter, bfeed, bmt, bnct, btrial, burn, channing, drug6mp, drughiv, hodg, kidney, kidrecurr, kidtran, larynx, lung, pneumon, psych, rats, std, stddiag, tongue, twins, Animals2, CrohnD, NOxEmissions, SiegelsEx, aircraft, airmay, alcohol, ambientNOxCH, bushfire, carrots, cloud, coleman, condroz, cushny, delivery, education, epilepsy, exAM, foodstamp, hbk, heart, kootenay, lactic, milk, pension, phosphor, pilot, possumDiv, pulpfiber, radarImage, salinity, starsCYG, telef, toxicity, vaso, wagnerGrowth, wood, AMSsurvey, Adler, Angell, Anscombe, Baumann, Bfox, Blackmoor, Burt, CanPop, Chile, Chirot, Cowles, Davis, DavisThin, Depredations, Duncan, Ericksen, Florida, Freedman, Friendly, Ginzberg, Greene, Guyer, Hartnagel, Highway1, Leinhardt, Mandel, Migration, Moore, Mroz, OBrienKaiser, Ornstein, Pottery, Prestige, Quartet, Robey, SLID, Sahlins, Salaries, Soils, States, Transact, UN, USPop, Vocab, WeightLoss, Womenlf, Wool, agriculture, animals, chorSub, flower, plantTraits, pluton, ruspini, votes.repub, xclara, affairs, azcabgptca, azdrg112, azpro, azprocedure, badhealth, fasttrakg, fishing, lbw, lbwgrp, loomis, mdvis, medpar, nuts, rwm, rwm1984, rwm5yr, ships, smoking, titanic, titanicgrp, Accident, Airline, Airq, Benefits, Bids, BudgetFood, BudgetItaly, BudgetUK, Bwages, CPSch3, CRANpackages, Capm, Car, Caschool, Catsup, Cigar, Cigarette, Clothing, Computers, Cracker, Crime, DM, Diamond, Doctor, DoctorAUS, DoctorContacts, Earnings, Electricity, Fair, Fatality, Fishing, Forward, FriendFoe, Garch, Gasoline, Griliches, Grunfeld, HC, HI, Hdma, Heating, Hedonic, Housing, Icecream, Journals, Kakadu, Ketchup, Klein, LaborSupply, Labour, MCAS, Males, Mathlevel, MedExp, Metal, Mode, ModeChoice, Mofa, Mroz, MunExp, NaturalPark, Nerlove, OFP, Oil, PSID, Participation, PatentsHGH, PatentsRD, Pound, Produc, RetSchool, SP500, Schooling, Somerville, Star, Strike, StrikeDur, StrikeNb, SumHes, Tobacco, Train, TranspEq, Treatment, Tuna, USFinanceIndustry, USclassifiedDocuments, USstateAbbreviations, UStaxWords, UnempDur, Unemployment, University, VietNamH, VietNamI, Wages, Wages1, Workinghours, Yen, Yogurt, bankingCrises, incomeInequality, nonEnglishNames, politicalKnowledge, PD, aldh2, apoeapoc, cf, crohn, fa, fsnps, hla, hr1420, l51, lukas, mao, mfblong, mhtdata, nep499, diamonds, economics, midwest, movies, mpg, msleep, presidential, seals, Arbuthnot, Bowley, Cavendish, ChestSizes, CushnyPeebles, CushnyPeeblesN, Dactyl, DrinksWages, Fingerprints, Galton, GaltonFamilies, Guerry, Jevons, Langren.all, Langren1644, Macdonell, MacdonellDF, Michelson, MichelsonSets, Minard.cities, Minard.temp, Minard.troops, Nightingale, OldMaps, PearsonLee, PolioTrials, Prostitutes, Pyx, Quarrels, Snow.deaths, Snow.polygons, Snow.pumps, Snow.streets, Wheat, Wheat.monarchs, Yeast, YeastD.mat, ZeaMays, barley, environmental, ethanol, melanoma, singer, Aids2, Animals, Boston, Cars93, Cushings, DDT, GAGurine, Insurance, Melanoma, OME, Pima.te, Pima.tr, Pima.tr2, Rabbit, Rubber, SP500, Sitka, Sitka89, Skye, Traffic, UScereal, UScrime, VA, abbey, accdeaths, anorexia, bacteria, beav1, beav2, biopsy, birthwt, cabbages, caith, cats, cement, chem, coop, cpus, crabs, deaths, drivers, eagles, epil, farms, fgl, forbes, galaxies, gehan, genotype, geyser, gilgais, hills, housing, immer, leuk, mammals, mcycle, menarche, michelson, minn38, motors, muscle, newcomb, nlschools, npk, npr1, oats, painters, petrol, quine, road, rotifer, ships, shrimp, shuttle, snails, steam, stormer, survey, synth.te, synth.tr, topo, waders, whiteside, wtloss, Cigar, Crime, EmplUK, Gasoline, Grunfeld, Hedonic, LaborSupply, Males, Produc, Snmesp, SumHes, Wages, baseball, AustralianElectionPolling, AustralianElections, EfronMorris, RockTheVote, UKHouseOfCommons, absentee, admit, bioChemists, ca2006, iraqVote, politicalInformation, presidentialElections, prussian, unionDensity, vote92, french_fries, smiths, tips, car.test.frame, car90, cu.summary, kyphosis, solder, stagec, PublicSchools, Bollen, CNES, Klein, Kmenta, Tests, bladder, cancer, cgd, colon, flchain, heart, kidney, leukemia, logan, lung, mgus, nwtco, ovarian, pbc, rats, stanford2, tobin, veteran, Arthritis, Baseball, BrokenMarriage, Bundesliga, Bundestag2005, Butterfly, CoalMiners, DanishWelfare, Employment, Federalist, Hitters, HorseKicks, Hospital, JobSatisfaction, JointSports, Lifeboats, NonResponse, OvaryCancer, PreSex, Punishment, RepVict, Saxony, SexualFun, SpaceShuttle, Suicide, Trucks, UKSoccer, VisualAcuity, VonBort, WeldonDice, WomenQueue, MatchIt.url, PErisk, SupremeCourt, Weimar, Zelig.url, approval, bivariate, coalition, coalition2, eidat, free1, free2, friendship, grunfeld, hoff, homerun, immi1, immi2, immi3, immi4, immi5, immigration, klein, kmenta, macro, mexico, mid, newpainters, sanction, sna.ex, swiss, tobin, turnout, voteincome, BCG, BtheB, CYGOB1, Forbes2000, GHQ, Lanza, agefat, aspirin, birthdeathrates, bladdercancer, clouds, epilepsy, foster, heptathlon, mastectomy, meteo, orallesions, phosphate, pistonrings, planets, plasma, polyps, polyps3, pottery, rearrests, respiratory, roomwidth, schizophrenia, schizophrenia2, schooldays, skulls, smoking, students, suicides, toothpaste, voting, water, watervoles, waves, weightgain, womensrole, Bechtoldt, Bechtoldt.1, Bechtoldt.2, Dwyer, Gleser, Gorsuch, Harman.5, Harman.8, Harman.political, Holzinger, Holzinger.9, Reise, Schmid, Thurstone, Thurstone.33, Tucker, ability, affect, bfi, bfi.dictionary, blot, burt, cities, cubits, cushny, epi, epi.bfi, epi.dictionary, galton, heights, income, iqitems, msq, neo, peas, sat.act, withinBetween, Bosco, CobarOre, Mammals, barro, engel, uis, dietox, koch, ohio, respdis, respiratory, seizure, sitka89, spruce, liver, portpirie, rain, summer, wavesurge, winter, arthritis, housing, bmw, danish, nidd.annual, nidd.thresh, siemens, sp.raw, spto87, Dyestuff, Dyestuff2, InstEval, Pastes, Penicillin, VerbAgg, cake, cbpp, grouseticks, sleepstudy\n"
     ]
    }
   ],
   "source": [
    "dataset_ids = data()['dataset_id'].tolist()\n",
    "dataset_ids_str = \", \".join(dataset_ids)\n",
    "print(dataset_ids_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cde336b-4599-4d5c-8e0f-0070d35e60b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AirPassengers, BJsales, BOD, Formaldehyde, HairEyeColor, InsectSprays, JohnsonJohnson, LakeHuron,\n",
      "LifeCycleSavings, Nile, OrchardSprays, PlantGrowth, Puromycin, Titanic, ToothGrowth, UCBAdmissions,\n",
      "UKDriverDeaths, UKgas, USAccDeaths, USArrests, USJudgeRatings, USPersonalExpenditure, VADeaths,\n",
      "WWWusage, WorldPhones, airmiles, airquality, anscombe, attenu, attitude, austres, cars, chickwts,\n",
      "co2, crimtab, discoveries, esoph, euro, faithful, freeny, infert, iris, islands, lh, longley, lynx,\n",
      "morley, mtcars, nhtemp, nottem, npk, occupationalStatus, precip, presidents, pressure, quakes,\n",
      "randu, rivers, rock, sleep, stackloss, sunspot.month, sunspot.year, sunspots, swiss, treering,\n",
      "trees, uspop, volcano, warpbreaks, women, acme, aids, aircondit, aircondit7, amis, aml, bigcity,\n",
      "brambles, breslow, calcium, cane, capability, catsM, cav, cd4, channing, city, claridge, cloth,\n",
      "co.transfer, coal, darwin, dogs, downs.bc, ducks, fir, frets, grav, gravity, hirose, islay, manaus,\n",
      "melanoma, motor, neuro, nitrofen, nodal, nuclear, paulsen, poisons, polar, remission, salinity,\n",
      "survival, tau, tuna, urine, wool, aids, alloauto, allograft, azt, baboon, bcdeter, bfeed, bmt, bnct,\n",
      "btrial, burn, channing, drug6mp, drughiv, hodg, kidney, kidrecurr, kidtran, larynx, lung, pneumon,\n",
      "psych, rats, std, stddiag, tongue, twins, Animals2, CrohnD, NOxEmissions, SiegelsEx, aircraft,\n",
      "airmay, alcohol, ambientNOxCH, bushfire, carrots, cloud, coleman, condroz, cushny, delivery,\n",
      "education, epilepsy, exAM, foodstamp, hbk, heart, kootenay, lactic, milk, pension, phosphor, pilot,\n",
      "possumDiv, pulpfiber, radarImage, salinity, starsCYG, telef, toxicity, vaso, wagnerGrowth, wood,\n",
      "AMSsurvey, Adler, Angell, Anscombe, Baumann, Bfox, Blackmoor, Burt, CanPop, Chile, Chirot, Cowles,\n",
      "Davis, DavisThin, Depredations, Duncan, Ericksen, Florida, Freedman, Friendly, Ginzberg, Greene,\n",
      "Guyer, Hartnagel, Highway1, Leinhardt, Mandel, Migration, Moore, Mroz, OBrienKaiser, Ornstein,\n",
      "Pottery, Prestige, Quartet, Robey, SLID, Sahlins, Salaries, Soils, States, Transact, UN, USPop,\n",
      "Vocab, WeightLoss, Womenlf, Wool, agriculture, animals, chorSub, flower, plantTraits, pluton,\n",
      "ruspini, votes.repub, xclara, affairs, azcabgptca, azdrg112, azpro, azprocedure, badhealth,\n",
      "fasttrakg, fishing, lbw, lbwgrp, loomis, mdvis, medpar, nuts, rwm, rwm1984, rwm5yr, ships, smoking,\n",
      "titanic, titanicgrp, Accident, Airline, Airq, Benefits, Bids, BudgetFood, BudgetItaly, BudgetUK,\n",
      "Bwages, CPSch3, CRANpackages, Capm, Car, Caschool, Catsup, Cigar, Cigarette, Clothing, Computers,\n",
      "Cracker, Crime, DM, Diamond, Doctor, DoctorAUS, DoctorContacts, Earnings, Electricity, Fair,\n",
      "Fatality, Fishing, Forward, FriendFoe, Garch, Gasoline, Griliches, Grunfeld, HC, HI, Hdma, Heating,\n",
      "Hedonic, Housing, Icecream, Journals, Kakadu, Ketchup, Klein, LaborSupply, Labour, MCAS, Males,\n",
      "Mathlevel, MedExp, Metal, Mode, ModeChoice, Mofa, Mroz, MunExp, NaturalPark, Nerlove, OFP, Oil,\n",
      "PSID, Participation, PatentsHGH, PatentsRD, Pound, Produc, RetSchool, SP500, Schooling, Somerville,\n",
      "Star, Strike, StrikeDur, StrikeNb, SumHes, Tobacco, Train, TranspEq, Treatment, Tuna,\n",
      "USFinanceIndustry, USclassifiedDocuments, USstateAbbreviations, UStaxWords, UnempDur, Unemployment,\n",
      "University, VietNamH, VietNamI, Wages, Wages1, Workinghours, Yen, Yogurt, bankingCrises,\n",
      "incomeInequality, nonEnglishNames, politicalKnowledge, PD, aldh2, apoeapoc, cf, crohn, fa, fsnps,\n",
      "hla, hr1420, l51, lukas, mao, mfblong, mhtdata, nep499, diamonds, economics, midwest, movies, mpg,\n",
      "msleep, presidential, seals, Arbuthnot, Bowley, Cavendish, ChestSizes, CushnyPeebles,\n",
      "CushnyPeeblesN, Dactyl, DrinksWages, Fingerprints, Galton, GaltonFamilies, Guerry, Jevons,\n",
      "Langren.all, Langren1644, Macdonell, MacdonellDF, Michelson, MichelsonSets, Minard.cities,\n",
      "Minard.temp, Minard.troops, Nightingale, OldMaps, PearsonLee, PolioTrials, Prostitutes, Pyx,\n",
      "Quarrels, Snow.deaths, Snow.polygons, Snow.pumps, Snow.streets, Wheat, Wheat.monarchs, Yeast,\n",
      "YeastD.mat, ZeaMays, barley, environmental, ethanol, melanoma, singer, Aids2, Animals, Boston,\n",
      "Cars93, Cushings, DDT, GAGurine, Insurance, Melanoma, OME, Pima.te, Pima.tr, Pima.tr2, Rabbit,\n",
      "Rubber, SP500, Sitka, Sitka89, Skye, Traffic, UScereal, UScrime, VA, abbey, accdeaths, anorexia,\n",
      "bacteria, beav1, beav2, biopsy, birthwt, cabbages, caith, cats, cement, chem, coop, cpus, crabs,\n",
      "deaths, drivers, eagles, epil, farms, fgl, forbes, galaxies, gehan, genotype, geyser, gilgais,\n",
      "hills, housing, immer, leuk, mammals, mcycle, menarche, michelson, minn38, motors, muscle, newcomb,\n",
      "nlschools, npk, npr1, oats, painters, petrol, quine, road, rotifer, ships, shrimp, shuttle, snails,\n",
      "steam, stormer, survey, synth.te, synth.tr, topo, waders, whiteside, wtloss, Cigar, Crime, EmplUK,\n",
      "Gasoline, Grunfeld, Hedonic, LaborSupply, Males, Produc, Snmesp, SumHes, Wages, baseball,\n",
      "AustralianElectionPolling, AustralianElections, EfronMorris, RockTheVote, UKHouseOfCommons,\n",
      "absentee, admit, bioChemists, ca2006, iraqVote, politicalInformation, presidentialElections,\n",
      "prussian, unionDensity, vote92, french_fries, smiths, tips, car.test.frame, car90, cu.summary,\n",
      "kyphosis, solder, stagec, PublicSchools, Bollen, CNES, Klein, Kmenta, Tests, bladder, cancer, cgd,\n",
      "colon, flchain, heart, kidney, leukemia, logan, lung, mgus, nwtco, ovarian, pbc, rats, stanford2,\n",
      "tobin, veteran, Arthritis, Baseball, BrokenMarriage, Bundesliga, Bundestag2005, Butterfly,\n",
      "CoalMiners, DanishWelfare, Employment, Federalist, Hitters, HorseKicks, Hospital, JobSatisfaction,\n",
      "JointSports, Lifeboats, NonResponse, OvaryCancer, PreSex, Punishment, RepVict, Saxony, SexualFun,\n",
      "SpaceShuttle, Suicide, Trucks, UKSoccer, VisualAcuity, VonBort, WeldonDice, WomenQueue, MatchIt.url,\n",
      "PErisk, SupremeCourt, Weimar, Zelig.url, approval, bivariate, coalition, coalition2, eidat, free1,\n",
      "free2, friendship, grunfeld, hoff, homerun, immi1, immi2, immi3, immi4, immi5, immigration, klein,\n",
      "kmenta, macro, mexico, mid, newpainters, sanction, sna.ex, swiss, tobin, turnout, voteincome, BCG,\n",
      "BtheB, CYGOB1, Forbes2000, GHQ, Lanza, agefat, aspirin, birthdeathrates, bladdercancer, clouds,\n",
      "epilepsy, foster, heptathlon, mastectomy, meteo, orallesions, phosphate, pistonrings, planets,\n",
      "plasma, polyps, polyps3, pottery, rearrests, respiratory, roomwidth, schizophrenia, schizophrenia2,\n",
      "schooldays, skulls, smoking, students, suicides, toothpaste, voting, water, watervoles, waves,\n",
      "weightgain, womensrole, Bechtoldt, Bechtoldt.1, Bechtoldt.2, Dwyer, Gleser, Gorsuch, Harman.5,\n",
      "Harman.8, Harman.political, Holzinger, Holzinger.9, Reise, Schmid, Thurstone, Thurstone.33, Tucker,\n",
      "ability, affect, bfi, bfi.dictionary, blot, burt, cities, cubits, cushny, epi, epi.bfi,\n",
      "epi.dictionary, galton, heights, income, iqitems, msq, neo, peas, sat.act, withinBetween, Bosco,\n",
      "CobarOre, Mammals, barro, engel, uis, dietox, koch, ohio, respdis, respiratory, seizure, sitka89,\n",
      "spruce, liver, portpirie, rain, summer, wavesurge, winter, arthritis, housing, bmw, danish,\n",
      "nidd.annual, nidd.thresh, siemens, sp.raw, spto87, Dyestuff, Dyestuff2, InstEval, Pastes,\n",
      "Penicillin, VerbAgg, cake, cbpp, grouseticks, sleepstudy\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "wrapped = textwrap.fill(dataset_ids_str, width=100)\n",
    "print(wrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51ea25fa-33a2-4e7e-a1fb-e7fce1148a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
      "1           5.1          3.5           1.4          0.2  setosa\n",
      "2           4.9          3.0           1.4          0.2  setosa\n",
      "3           4.7          3.2           1.3          0.2  setosa\n",
      "4           4.6          3.1           1.5          0.2  setosa\n",
      "5           5.0          3.6           1.4          0.2  setosa\n"
     ]
    }
   ],
   "source": [
    "iris = data('iris')\n",
    "print(iris.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "813788d9-f893-4c21-9d66-f4fc134463a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mazda RX4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mazda RX4 Wag</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datsun 710</th>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hornet 4 Drive</th>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hornet Sportabout</th>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  \\\n",
       "Mazda RX4          21.0    6  160.0  110  3.90  2.620  16.46   0   1     4   \n",
       "Mazda RX4 Wag      21.0    6  160.0  110  3.90  2.875  17.02   0   1     4   \n",
       "Datsun 710         22.8    4  108.0   93  3.85  2.320  18.61   1   1     4   \n",
       "Hornet 4 Drive     21.4    6  258.0  110  3.08  3.215  19.44   1   0     3   \n",
       "Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3   \n",
       "\n",
       "                   carb  \n",
       "Mazda RX4             4  \n",
       "Mazda RX4 Wag         4  \n",
       "Datsun 710            1  \n",
       "Hornet 4 Drive        1  \n",
       "Hornet Sportabout     2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtcars = data('mtcars')\n",
    "mtcars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "863db9aa-b89d-46f1-96e7-5466e0eefdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d2541d8-3385-4261-a9cb-383437161117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b08b4cb-f029-4fe1-9502-6631e6556c58",
   "metadata": {},
   "source": [
    "iris2 = datasets.load_iris()\n",
    "print(iris2.data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35f65633-9704-44d9-ad22-42b208496765",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iris2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(iris2\u001b[38;5;241m.\u001b[39mdata, columns \u001b[38;5;241m=\u001b[39m iris2\u001b[38;5;241m.\u001b[39mfeature_names)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(df2\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'iris2' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df2 = pd.DataFrame(iris2.data, columns = iris2.feature_names)\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af90f514-7980-41be-89be-48c2f65f07be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from seaborn) (2.1.3)\n",
      "Requirement already satisfied: pandas>=1.2 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from seaborn) (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa99b86a-6664-48ad-9609-ef1524c2878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f7dcd68-ccdb-4786-a110-9316110b1c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anagrams', 'anscombe', 'attention', 'brain_networks', 'car_crashes', 'diamonds', 'dots', 'dowjones', 'exercise', 'flights', 'fmri', 'geyser', 'glue', 'healthexp', 'iris', 'mpg', 'penguins', 'planets', 'seaice', 'taxis', 'tips', 'titanic']\n"
     ]
    }
   ],
   "source": [
    "print(sns.get_dataset_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7787be7f-e384-4419-b13e-620b3caa1d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_bill   tip     sex smoker  day    time  size\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4\n"
     ]
    }
   ],
   "source": [
    "tips = sns.load_dataset('tips')\n",
    "print(tips.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ef98e1b-a51c-4291-b155-fc748b37996f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (0.14.4)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from statsmodels) (2.1.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from statsmodels) (1.15.3)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from statsmodels) (2.2.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from statsmodels) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3227365b-4fab-45f0-ad6c-7995f021494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba39f8df-9ce1-48cb-a991-102c873ec65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    TOTEMP  GNPDEFL       GNP   UNEMP   ARMED       POP    YEAR\n",
      "0  60323.0     83.0  234289.0  2356.0  1590.0  107608.0  1947.0\n",
      "1  61122.0     88.5  259426.0  2325.0  1456.0  108632.0  1948.0\n",
      "2  60171.0     88.2  258054.0  3682.0  1616.0  109773.0  1949.0\n",
      "3  61187.0     89.5  284599.0  3351.0  1650.0  110929.0  1950.0\n",
      "4  63221.0     96.2  328975.0  2099.0  3099.0  112075.0  1951.0\n"
     ]
    }
   ],
   "source": [
    "dataset = sm.datasets.longley.load_pandas().data\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43ef3fd7-0697-4aec-a012-9fb64084007d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (4.5 kB)\n",
      "Collecting tensorflow-datasets\n",
      "  Downloading tensorflow_datasets-4.9.9-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.74.0-cp313-cp313-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (3.12.1)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.3-cp313-cp313-macosx_10_13_universal2.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: pillow in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (11.1.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Collecting dm-tree (from tensorflow-datasets)\n",
      "  Downloading dm_tree-0.1.9-cp313-cp313-macosx_10_13_universal2.whl.metadata (2.4 kB)\n",
      "Collecting etils>=1.9.1 (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets)\n",
      "  Downloading etils-1.13.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting immutabledict (from tensorflow-datasets)\n",
      "  Downloading immutabledict-4.2.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting promise (from tensorflow-datasets)\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: psutil in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow-datasets) (5.9.0)\n",
      "Requirement already satisfied: pyarrow in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow-datasets) (19.0.0)\n",
      "Collecting simple_parsing (from tensorflow-datasets)\n",
      "  Downloading simple_parsing-0.1.7-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting tensorflow-metadata (from tensorflow-datasets)\n",
      "  Downloading tensorflow_metadata-1.17.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: toml in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow-datasets) (4.67.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Collecting einops (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: fsspec in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (2025.3.2)\n",
      "Collecting importlib_resources (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: zipp in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (3.21.0)\n",
      "Requirement already satisfied: rich in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.17.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: attrs>=18.2.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from dm-tree->tensorflow-datasets) (24.3.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Collecting docstring-parser<1.0,>=0.15 (from simple_parsing->tensorflow-datasets)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting googleapis-common-protos<2,>=1.56.4 (from tensorflow-metadata->tensorflow-datasets)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Downloading tensorflow-2.20.0-cp313-cp313-macosx_12_0_arm64.whl (200.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.7/200.7 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading grpcio-1.74.0-cp313-cp313-macosx_11_0_universal2.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.3-cp313-cp313-macosx_10_13_universal2.whl (663 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.8/663.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading tensorflow_datasets-4.9.9-py3-none-any.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading etils-1.13.0-py3-none-any.whl (170 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading dm_tree-0.1.9-cp313-cp313-macosx_10_13_universal2.whl (175 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading immutabledict-4.2.1-py3-none-any.whl (4.7 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp313-cp313-macosx_11_0_arm64.whl (354 kB)\n",
      "Downloading simple_parsing-0.1.7-py3-none-any.whl (112 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading tensorflow_metadata-1.17.2-py3-none-any.whl (31 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Building wheels for collected packages: promise\n",
      "\u001b[33m  DEPRECATION: Building 'promise' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'promise'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21482 sha256=ad6aa998b072af46e125ee3d6f7026a4426d49cb1d9f7769c4729c4099102a7a\n",
      "  Stored in directory: /Users/md.hossain/Library/Caches/pip/wheels/8f/46/1c/1f4e5d73a20eb816ead5014e97cdeb3928cf314fc46c7bab61\n",
      "Successfully built promise\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, promise, optree, opt_einsum, ml_dtypes, importlib_resources, immutabledict, grpcio, googleapis-common-protos, google_pasta, gast, etils, einops, docstring-parser, astunparse, absl-py, tensorflow-metadata, tensorboard, simple_parsing, dm-tree, keras, tensorflow, tensorflow-datasets\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/27\u001b[0m [tensorflow-datasets]nsorflow-datasets]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 astunparse-1.6.3 dm-tree-0.1.9 docstring-parser-0.17.0 einops-0.8.1 etils-1.13.0 flatbuffers-25.2.10 gast-0.6.0 google_pasta-0.2.0 googleapis-common-protos-1.70.0 grpcio-1.74.0 immutabledict-4.2.1 importlib_resources-6.5.2 keras-3.11.3 libclang-18.1.1 ml_dtypes-0.5.3 namex-0.1.0 opt_einsum-3.4.0 optree-0.17.0 promise-2.3 simple_parsing-0.1.7 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 tensorflow-datasets-4.9.9 tensorflow-metadata-1.17.2 termcolor-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc87bf8c-36cc-4c51-9537-23cf5885f97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc80d73-66c4-4d82-922a-fbbc52f123c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Variant folder /Users/md.hossain/tensorflow_datasets/mnist/3.0.1 has no dataset_info.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /Users/md.hossain/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a2e52258af45419c5cd783789d11ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5901ff056d94b21a3c145484298edeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce85fbad988a4cf8a8b003a3fbc2c252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds, info = tfds.load('mnist', with_info=True, as_supervised=True)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c50795f0-d3f0-41d9-8388-13690737c107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: pillow in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (11.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9e07f0-54c8-4f6e-bdfb-0bef2c972ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5642ba2d-4417-44a4-aa32-acac63569031",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m (train_images, train_labels), (test_images, test_labels) \u001b[38;5;241m=\u001b[39m mnist\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_images\u001b[38;5;241m.\u001b[39mshape, train_labels\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mnist' is not defined"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(train_images.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c52f7bd-911d-4b11-8697-40351eb20030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (5.24.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from plotly) (9.0.0)\n",
      "Requirement already satisfied: packaging in /Users/md.hossain/analytics/setup/anaconda3/lib/python3.13/site-packages (from plotly) (24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65fb18fb-3856-409a-a6d2-af85d4a6f37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7330488e-fe03-43dd-b60e-77bbb9a6637b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       country continent  year  lifeExp       pop   gdpPercap iso_alpha  \\\n",
      "0  Afghanistan      Asia  1952   28.801   8425333  779.445314       AFG   \n",
      "1  Afghanistan      Asia  1957   30.332   9240934  820.853030       AFG   \n",
      "2  Afghanistan      Asia  1962   31.997  10267083  853.100710       AFG   \n",
      "3  Afghanistan      Asia  1967   34.020  11537966  836.197138       AFG   \n",
      "4  Afghanistan      Asia  1972   36.088  13079460  739.981106       AFG   \n",
      "\n",
      "   iso_num  \n",
      "0        4  \n",
      "1        4  \n",
      "2        4  \n",
      "3        4  \n",
      "4        4  \n"
     ]
    }
   ],
   "source": [
    "gapminder = data.gapminder()\n",
    "print(gapminder.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87e6608d-5db0-40b0-8ec3-09fc9806bd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://docs.google.com/spreadsheets/d/19ReQlRfDQHcV1OFUnmVkiFY_1IrJeOR0g1RmrjfjMD4/export?format=csv&gid=764977169\n"
     ]
    }
   ],
   "source": [
    "gs1 = 'https://docs.google.com/spreadsheets/d/'\n",
    "sheetid = '19ReQlRfDQHcV1OFUnmVkiFY_1IrJeOR0g1RmrjfjMD4'\n",
    "gs2 = '/export?format=csv&gid='\n",
    "gid = '764977169'\n",
    "gsurl = gs1 + sheetid + gs2 + gid\n",
    "print(gsurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7024c54-e718-4558-9910-5ec3e5527fe8",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 401: Unauthorized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m orders_df \u001b[38;5;241m=\u001b[39m orders_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(gsurl)\n\u001b[1;32m      3\u001b[0m orders_df\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/analytics/setup/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/analytics/setup/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/analytics/setup/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/analytics/setup/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/analytics/setup/anaconda3/lib/python3.13/site-packages/pandas/io/common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m _get_filepath_or_buffer(\n\u001b[1;32m    729\u001b[0m     path_or_buf,\n\u001b[1;32m    730\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m    731\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m    732\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    733\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    734\u001b[0m )\n\u001b[1;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m~/analytics/setup/anaconda3/lib/python3.13/site-packages/pandas/io/common.py:384\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    383\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urlopen(req_info) \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    385\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m~/analytics/setup/anaconda3/lib/python3.13/site-packages/pandas/io/common.py:289\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/analytics/setup/anaconda3/lib/python3.13/urllib/request.py:189\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, context)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[0;32m~/analytics/setup/anaconda3/lib/python3.13/urllib/request.py:495\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    494\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 495\u001b[0m     response \u001b[38;5;241m=\u001b[39m meth(req, response)\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/analytics/setup/anaconda3/lib/python3.13/urllib/request.py:604\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 604\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    605\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, request, response, code, msg, hdrs)\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/analytics/setup/anaconda3/lib/python3.13/urllib/request.py:533\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    532\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/analytics/setup/anaconda3/lib/python3.13/urllib/request.py:466\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    465\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 466\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/analytics/setup/anaconda3/lib/python3.13/urllib/request.py:613\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 613\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 401: Unauthorized"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "orders_df = orders_df = pd.read_csv(gsurl)\n",
    "orders_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0167492-c7c2-44c7-b265-acffff1be167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "requests.head(gsurl, allow_redirects=True, timeout =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68c45194-86f7-4267-bd5e-03e3af5bd2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlrd\n",
      "  Downloading xlrd-2.0.2-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Downloading xlrd-2.0.2-py2.py3-none-any.whl (96 kB)\n",
      "Installing collected packages: xlrd\n",
      "Successfully installed xlrd-2.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8044411-7386-4511-b220-5e71f594fbe9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(url, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxlrd\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'url' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(url, engine=\"xlrd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dedec3d5-fa0f-477d-a65e-1ad9ea4a180b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faef5d6c-0122-44ad-8094-369a684d280c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
